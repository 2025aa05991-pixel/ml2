# Breast Cancer Wisconsin (Diagnostic) - ML Classification

**BITS Pilani - ML Assignment 2**  
**Author:** Vivek Chaudhary  
**Date:** February 2026  
**Deadline:** 15-Feb-2026 23:59

---

## üéØ Problem Statement

Develop a complete machine learning solution for **binary classification** on the Breast Cancer Wisconsin (Diagnostic) dataset. The goal is to predict whether a tumor is **malignant (M)** or **benign (B)** based on 30 real-valued features computed from digitized images of fine needle aspirate (FNA) of breast mass.

This assignment demonstrates:
- Training and evaluation of 6 different ML models
- Comprehensive performance comparison using 6 metrics per model
- Deployment of an interactive Streamlit web application
- Best practices in ML pipeline design, validation, and deployment

---

## üìä Dataset Description

**Name:** Breast Cancer Wisconsin (Diagnostic) Dataset  
**Source:** [Kaggle - UCI ML Repository](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)  
**Kaggle URL:** https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data

### Key Characteristics:
- **Instances:** 569 samples
- **Features:** 30 real-valued features (all numeric)
- **Target Variable:** `diagnosis`
  - **M** = Malignant (positive class)
  - **B** = Benign (negative class)
- **Missing Values:** None
- **Class Distribution:**
  - Malignant: 212 (37.3%)
  - Benign: 357 (62.7%)

### Feature Groups:
The 30 features are computed for each cell nucleus and include:
1. **Mean values** (10 features): radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, fractal dimension
2. **Standard error** (10 features): SE of the above measurements
3. **Worst values** (10 features): Mean of the three largest values

### Why This Dataset Meets Requirements:
‚úÖ **Binary Classification:** Two classes (M/B)  
‚úÖ **‚â•500 Instances:** 569 samples  
‚úÖ **‚â•12 Features:** 30 numeric features  
‚úÖ **Clean Data:** No missing values  
‚úÖ **Real-world Application:** Medical diagnosis use case

---

## ü§ñ Models Implemented

Six machine learning models were trained and evaluated on the same dataset:

1. **Logistic Regression** (with StandardScaler)
2. **Decision Tree Classifier**
3. **K-Nearest Neighbors (KNN)** (with StandardScaler, k=5)
4. **Naive Bayes** (Gaussian)
5. **Random Forest Classifier** (100 estimators)
6. **XGBoost Classifier** (Gradient Boosting)

### Training Configuration:
- **Random State:** 42 (for reproducibility)
- **Train-Test Split:** 80-20 with stratification
- **Class Imbalance Handling:** `class_weight='balanced'` applied when imbalance ratio > 0.20
- **Preprocessing:**
  - Median imputation for missing values (if any)
  - StandardScaler for LR and KNN
  - No scaling for tree-based models (DT, RF, XGBoost)

---

## üìà Model Comparison Table

| Model | Accuracy | AUC | Precision | Recall | F1 | MCC |
|-------|----------|-----|-----------|--------|----|----|
| Logistic Regression | 0.9737 | 0.9934 | 0.9535 | 0.9535 | 0.9535 | 0.9431 |
| Random Forest | 0.9649 | 0.9923 | 0.9535 | 0.9302 | 0.9417 | 0.9229 |
| XGBoost | 0.9649 | 0.9911 | 0.9318 | 0.9535 | 0.9425 | 0.9224 |
| KNN | 0.9649 | 0.9906 | 0.9535 | 0.9302 | 0.9417 | 0.9228 |
| Naive Bayes | 0.9298 | 0.9832 | 0.9048 | 0.8837 | 0.8941 | 0.8466 |
| Decision Tree | 0.9474 | 0.9244 | 0.9302 | 0.9070 | 0.9185 | 0.8851 |

**Notes:**
- Table shows test set performance (114 samples)
- Sorted by F1 Score (descending)
- All metrics rounded to 4 decimal places
- Metrics computed with **malignant (M) as positive class**

### Metric Definitions:
- **Accuracy:** Overall correctness
- **AUC:** Area Under ROC Curve (binary classification)
- **Precision:** True Positives / (True Positives + False Positives)
- **Recall:** True Positives / (True Positives + False Negatives)
- **F1:** Harmonic mean of Precision and Recall
- **MCC:** Matthews Correlation Coefficient (-1 to +1)

---

## üîç Per-Model Observations

### 1. Logistic Regression ‚≠ê **Best Overall**
- **Strengths:** Highest accuracy (97.37%), best AUC (0.9934), and top F1 score (0.9535)
- **Why it works:** Linear separability with StandardScaler normalization; well-suited for medical diagnosis with balanced precision-recall
- **Use case:** Production deployment for high-stakes medical prediction

### 2. Random Forest
- **Strengths:** Strong ensemble performance (F1: 0.9417), excellent AUC (0.9923), robust to outliers
- **Why it works:** Handles non-linear patterns via multiple decision trees; good generalization
- **Trade-off:** Slightly lower recall than Logistic Regression

### 3. XGBoost
- **Strengths:** Competitive F1 (0.9425), highest recall (0.9535), efficient gradient boosting
- **Why it works:** Advanced boosting ensures minimal false negatives (critical in cancer detection)
- **Use case:** When minimizing missed malignant cases is priority

### 4. KNN
- **Strengths:** Solid F1 (0.9417), simple interpretability, no training phase
- **Why it works:** Similar tumors cluster in feature space after scaling
- **Trade-off:** Slower prediction time; sensitive to k selection

### 5. Naive Bayes
- **Strengths:** Fast training/prediction, decent performance (F1: 0.8941)
- **Limitations:** Assumes feature independence (violated in correlated features)
- **Use case:** Baseline model or real-time applications with acceptable accuracy

### 6. Decision Tree
- **Strengths:** Fully interpretable rules, no preprocessing needed
- **Limitations:** Lowest AUC (0.9244), prone to overfitting on complex patterns
- **Use case:** When model explainability is mandatory (regulatory requirements)

### Key Insights:
- **Scaling matters:** LR and KNN benefit significantly from StandardScaler
- **Ensemble advantage:** RF and XGBoost show consistent performance across metrics
- **Recall priority:** For cancer detection, XGBoost's high recall (95.35%) minimizes false negatives
- **Production choice:** Logistic Regression offers best balance of performance, speed, and interpretability

---

## üöÄ Deployment Instructions

### Prerequisites:
- GitHub account
- Streamlit Community Cloud account (free)

### Step-by-Step Deployment:

#### 1. **Prepare Repository**
```bash
# Initialize Git repository
git init
git add .
git commit -m "Initial commit - Breast Cancer ML App"

# Push to GitHub
git remote add origin <your-github-repo-url>
git branch -M main
git push -u origin main
```

#### 2. **Train Models Locally**
Before deploying, train all models and generate artifacts:
```bash
python model/train_all.py
```

This creates:
- `model/saved_models/*.pkl` (6 model files)
- `model/metrics_comparison.csv` (performance table)
- `model/expected_schema.json` (feature schema)
- `sample_test.csv` (10 sample instances)

**‚ö†Ô∏è Important:** Commit these files to your repository!
```bash
git add model/saved_models/ model/*.csv model/*.json sample_test.csv
git commit -m "Add trained models and artifacts"
git push
```

#### 3. **Deploy on Streamlit Community Cloud**
1. Go to [share.streamlit.io](https://share.streamlit.io)
2. Sign in with GitHub
3. Click **"New app"**
4. Select:
   - **Repository:** `<your-username>/<your-repo-name>`
   - **Branch:** `main`
   - **Main file path:** `app.py`
5. Click **"Deploy!"**

#### 4. **Wait for Deployment**
- App typically deploys in 2-5 minutes
- Streamlit installs dependencies from `requirements.txt`
- Check logs for any errors

#### 5. **Access Your App**
- URL format: `https://<your-app-name>.streamlit.app`
- Share this URL for public access

### Common Deployment Issues:
- **Missing dependencies:** Ensure all packages in `requirements.txt` have correct versions
- **Model files not found:** Verify `model/saved_models/*.pkl` files are committed
- **Import errors:** Check package name consistency (e.g., `scikit-learn` vs `sklearn`)

---

## üñ•Ô∏è Local Development

### Setup:
```bash
# Clone repository
git clone <your-repo-url>
cd <repo-folder>

# Install dependencies
pip install -r requirements.txt

# Train models
python model/train_all.py

# Run Streamlit app
streamlit run app.py
```

### File Structure:
```
project-folder/
‚îú‚îÄ‚îÄ app.py                          # Streamlit web application
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îú‚îÄ‚îÄ README.md                       # This file
‚îú‚îÄ‚îÄ sample_test.csv                 # Sample test data (generated)
‚îî‚îÄ‚îÄ model/
    ‚îú‚îÄ‚îÄ train_all.py                # Training pipeline
    ‚îú‚îÄ‚îÄ metrics_comparison.csv      # Model performance (generated)
    ‚îú‚îÄ‚îÄ expected_schema.json        # Feature schema (generated)
    ‚îî‚îÄ‚îÄ saved_models/               # Trained models (generated)
        ‚îú‚îÄ‚îÄ logistic_regression.pkl
        ‚îú‚îÄ‚îÄ decision_tree.pkl
        ‚îú‚îÄ‚îÄ knn.pkl
        ‚îú‚îÄ‚îÄ naive_bayes.pkl
        ‚îú‚îÄ‚îÄ random_forest.pkl
        ‚îî‚îÄ‚îÄ xgboost.pkl
```

---

## ‚úÖ Features Implemented

### Streamlit App Capabilities:
- ‚úÖ **CSV Upload:** Test data upload with schema validation
- ‚úÖ **Model Selection:** Dropdown to choose any of 6 models
- ‚úÖ **6 Metrics Display:** Accuracy, AUC, Precision, Recall, F1, MCC
- ‚úÖ **Confusion Matrix:** Visual representation of predictions
- ‚úÖ **Classification Report:** Detailed per-class metrics
- ‚úÖ **Schema Validation:** Automatic checks for correct column names/types
- ‚úÖ **Sample CSV Download:** Template for user test data
- ‚úÖ **Model Comparison Table:** Side-by-side performance analysis
- ‚úÖ **Results Export:** Download predictions as CSV
- ‚úÖ **Interactive Visualizations:** Bar charts, gradient tables

### Error Handling:
- Missing columns detection
- Extra columns warning
- Missing values notification
- File format validation
- Graceful error messages

---

## üìÑ Academic Integrity & Customization

### Original Work Statement:
This project represents original work completed for BITS Pilani ML Assignment 2. All code, documentation, and analysis are authored by the student. The commit history in the GitHub repository demonstrates incremental development and personal customization.

### Customization Evidence:
- Custom preprocessing pipeline with median imputation
- Automated class imbalance detection (threshold: 0.20)
- Enhanced Streamlit UI with 3-tab layout
- Comprehensive error validation system
- Original dataset analysis and model observations

### BITS Virtual Lab Proof:
**Required for PDF Submission:**
1. Open BITS Virtual Lab environment
2. Clone this repository
3. Run: `streamlit run app.py`
4. Take screenshot showing:
   - Terminal with command execution
   - Browser with running Streamlit app
   - Visible BITS Lab desktop/taskbar
5. Include screenshot in final PDF submission

---

## üìù Final Submission Checklist

- [x] **Repository Link:** GitHub repo is public and accessible
- [x] **Streamlit App Link:** Deployed app opens without errors
- [x] **App Functionality:** All features working (upload, predict, compare, download)
- [x] **README Complete:** Problem, dataset, models, comparison, observations included
- [x] **Trained Models:** All 6 `.pkl` files committed to repo
- [x] **Metrics File:** `metrics_comparison.csv` available
- [x] **Sample CSV:** `sample_test.csv` downloadable in app
- [x] **requirements.txt:** All dependencies listed with versions
- [x] **PDF Prepared:** Includes README content + BITS Lab screenshot + live links
- [x] **Deadline Check:** Submission before 15-Feb-2026 23:59
- [ ] **Final Submission:** Clicked "Submit" (not "Save as Draft")

### Submission Components:
1. **GitHub Repo URL:** `https://github.com/<your-username>/<repo-name>`
2. **Live Streamlit App URL:** `https://<app-name>.streamlit.app`
3. **PDF Document containing:**
   - This complete README
   - BITS Lab screenshot
   - Live app link and repo link
   - Model comparison table

---

## üôè Acknowledgments

- **Dataset:** UCI Machine Learning Repository via Kaggle
- **Frameworks:** scikit-learn, XGBoost, Streamlit
- **Institution:** BITS Pilani

---

## üìß Contact

For questions or issues, please create an issue in the GitHub repository or contact through BITS portal.

---

**License:** MIT (for educational purposes)  
**Last Updated:** February 2026
